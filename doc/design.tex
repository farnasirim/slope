\chapter{Design of Slope}
\label{chap:design}


\section{Design goals}

Slope aims to provide a migration mechanism to applications to allow them to
seamlessly move their data structures, and as a result, their corresponding
operations, across their instances.

The most important design goal of Slope is being pluggable in existing
applications which work with their data in a partitionable way. That means if
the system designer has already came up with a way to partition
application data and computation into units that can be run independently on a
single machine, the task of integrating Slope into the system to make its data
structures or more complex computation units migratable should be trivial.

To be more specific, we aim for zero modification to the internals of the
application and minimal addition to the API of the computation unit to
correctly define its behavior during its life cycle in Slope.

The migration delay which we define as the elapsed time since the start of the
migration of an object until it is successfully migrated is an important
performance metric in Slope. However, directly measuring this duration may fail
in reflecting how the migration process impacts the application. Some
applications may prioritize responsiveness and would trade off some of their
throughput during the migration process to keep their tail latencies low.
Similarly an application may choose the opposite or any scenario in the middle.
Therefore it makes more sense to define migration performance from the view
point of the application based on how \emph{its} performance metrics degrade
as a result of the migration. Therefore while there is value in keeping the
migration delay small, we prioritize maximizing the \emph{usefulness} of the
application in the distributed setting during the migration.

\begin{figure}[H]
\centering

\ensurepdffromsvg{design-goals-pluggable.drawio}
\includegraphics[width=0.5\textwidth]{design-goals-pluggable.drawio}
\caption{
    Figure shows how slope allows the already partitioned units of
    data/computation to be migrated across machines. However a need for request
    routing between the machines is introduced. This along with similar issues
    will be discussed in \TODO{a future section}.
}
\label{fig:designgoalspluggable}
\end{figure}

\section{Platform}
Applications have to call into Slope for initiating and carrying on the
migration operations. Since Slope requires intimate access to the application
memory, we need to carefully define what applications are supported
before discussing API and interactions.

We have chosen C++ as the platform to implement Slope, mainly because we need
to directly access process memory and manage the way it is allocated and used.
Whether or not these limitations can be eliminated, for example by using slope
as a service or like a sidecar process, as opposed to a library are future
research directions.

On the flip side, as a result of the Applications conforming to the C++
allocation model which is used throughout the language and the standard
template library, much of already existing C++ code can be quickly made
migratable through Slope. STL containers for example, can be made migratable as long as they are given Slope's allocator for their allocator type parameter.

\begin{figure}[H]
\begin{alltt}
// Declaration of std::vector in the STL
template<
    class T,
    \textbf{class Allocator = std::allocator<T>}
> class vector;

template<typename T>
using mig_vector = std::vector<T, slope::memory::Allocator<T>>;

\end{alltt}
\caption{
\texttt{mig\_vector<T>} wraps \texttt{std{::}vector<T, Allocator<T>>}, setting
its allocator type to one that slope provides. Objects of type
\texttt{mig\_vector<T>} are migratable as a result. Similarly
}
\end{figure}





\begin{figure}[H]
\begin{alltt}
// Declaration of std::vector in the STL
template<
    class T,
    \textbf{class Allocator = std::allocator<T>}
> class vector;

template<typename T>
using mig_vector = std::vector<T, slope::memory::Allocator<T>>;

template<class T, class Allocator>
class UserDefinedType \{
  static inline Allocator allocator;
  T *ptr_;
 public:
  template<typename... Args>
  UserDefinedType(Args&&... args):
    ptr_(\textbf{new (allocator.allocate(1))} T(std::forward<Args>(args)...)) \{ \}
  // ...
\};

\end{alltt}
\caption{
Similar to the case with \texttt{std{::}vector<T, Allocator>},
\texttt{UserDefinedType<T, Allocator>} is also migratable since it can work
with a supplied allocator that conforms to C++ allocator named requirement.
}
\end{figure}


\TODO{discuss threading? or somewhere else?}


\section{Architecture}

\section{Computation model}
Fundamentally every server has to be able to host an incoming object.
Since everything is async, this means that the object must know how to
"register" itself upon arrival in the remote node. Be it exposing a particular
api on a unix domain socket, or adding itself as an observer or worker to a blah.

\section{???}

Other rpc's are pluggable into slope.
An elaborate rpc inside won't make too much of a difference: very small number of messages exchanged upon migrations

We believe rdma must be used the way more mature resources are used, and must not require an exclusive perimeter of cpu-bound threads and lots of memory and whatnot is dedicated to it.

One migration destination per node
\TODO{For the cases similar to this one where we discussed a better solution but
I'm currently implementing a simpler solution (e.g. allocation),
is it ok to just talk about and
provide the final solution without mentioning my more trivial implementation,
even if I never implement the better version (for things that are not on
the critical path of a particular requirement and do not affect benchmarks)?}

\section{Protocol}
src: migrating n chunks
snk: send them

src: these are the n addrs
snk: pinned

src: prefill at address x, y, z, etc.
snk: got all prefills. Hand over the ownership

snk: locked, clear to read anything you want. x, y, z are dirty, and I'll also fill x for you
src: read y, z


\section{Slope internals}

instances mmap a mutual (fixed possibly at run-time) chunk of virtual address. This is called the migratable memory or slope memory.
We keep a thread local context stack which keeps track of the owner of each memory allocation. \TODO{Sequence diagram-like figure, denoting the ownership stack
next to the function activation record stack of the thread}.
- The ith machine owns the i/n'th section of the memory, assuming the machines have equal memory. Machines use a two level memory
allocation scheme, in which they ask for large chunks (e.g. 4Gb) from other nodes in the cluster to make sure we do not exhaust
the address space that each node owns. This will eliminate the need for a centralized way of keeping track of object allocations.
Applications can use their own memory allocator over the reserved regions of the shared address space that they have allocated.
Deallocations return the memory to the owner of the big segment periodically, off the critical path. \TODO{These are tricky.. revisit}

Provide definitions: source/host: current owner, destination/remote: future owner

- source acquires destination's migration lock to initiate the transfer
    - we use memcached
\TODO{Do we even need to mention this? Instead: Max K concurrent migrations to the same node are possible, K must be known at init time}

- Migration happens in two separate steps: prepare, and execute. Before execute
  is called, the owner of the data structure is always the source. Up until then
  routines at the source are allowed to read and write to the data structure.
  After a call to prepare, the source is no longer allowed to call into
  procedures which allocate memory to or deallocate memory from the data structure. Typically all const qualified methods in c++ 
  are safe to be called after a call to prepare, however not every safe procedure is necessarily const qualified (e.g. updating an element in a vector)
  At the call to execute, the source is no longer allowed to write to the data structure and yields the ownership. Its reads will also return stale values.
  We cannot effectively mprotect away all of the memory that the data structure uses. A failed call will result in a SIGSEGV with no general way of
  recovering from it.

  - It is the responsibility of the application to prevent the program from falling in one of these restricted paths.


\TODO{sequence diagram}
Hello

%  - Prefetch step happens in the prepare phase. source walks through the pages one by one, mprotects them to readonly, and
%    sends them to the corresponding addresses over RDMA.
%  
%    - This step is optional. If the data structure is under heavy usage and most of the memory is being touched, this
%    will only lengthen the migration process, during which the source cannot allocate/deallocate to the object that is being
%    migrated, without much improvement towards decreasing the handoff time, during which
%    none of the two machines have read or write access to the data structure.
%  
%  
%  ** Idea: From the call to execute, until when the source tells the sink about the call and send the
%  dirty pages that it needs to pull, we are losing time. What if the source pushes a few of the pages
%  based on a parameter that we optimize, to leverage the bandwidth during the idle time?
%   - I think regardless of the size of the data structure, this is a useful approach: If it's big,
%   only a small ratio is dirtied in between the phase changes and if it's small, then well, it's already small.
%   Since we can send 100Gb/s = 100Mb/ms, this is even close to the rate at which we dirty the pages, we win. \TODO{ This is not possible. The target memory is not
%   pinned before we tell them we're going to migrate into that specific part of their memory} \TODO{NO! this is happening after the prefill. The point here is to start the final transfer phase to make the handoff faster, not to make the whole migration process faster, which we don't really care that much about}
%   \TODO{How do we choose which pages to prefill? Can they express interest? Should we first send the mig_ptr
%   object headers to quickly generate the misses?}
%  
%  \section{Handling failures}
%  Migrations effectively allow us to persist a correct state of the data structure: We have a snapshot at migration time
%  
%  If a node goes away, we don't lose anything because of the point to point
%  nature of node communications. Every node knows who has allocated its memory
%  and can evict those leases if it desirable. No application fault tolerance
%  features provided aside from snapshots at migration time.
%  
%  
%  \section{Building systems on top of slope}
%  Discovery: can be done several ways: one way: lazy forwarding, keeping timestamps
%  of the migrations to figure out who knows the most recent information, 
%  Arp like protocol, 

% metric: change of (throughput per byte). What about the total time?
\TODO{Should this be in the evaluation section}
\TODO{Where should I raise the discussion about how these objects must be
used?}
