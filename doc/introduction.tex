\chapter{Introduction}
\label{chap:introduction}

\section{Locality in distributed applications}
Resource requirements of typical workloads in data intensive applications well surpass the
capacity of a single machine. 
Application programmers design distributed applications running on clusters of
machines to
meet the storage and computation requirements of these workloads. Therefore
designing applications that can scale across many machines becomes important as
resource requirements increase over time.


Throughout this document, we will use the term \emph{system} to refer to
kinds of software that accomplish an infrastructural goal. They are aimed at
taking away certain pains from higher level software. High level software
usually runs and depends on one or more \emph{systems}.
Conversely, we use the term \emph{application} to refer to higher level
software that makes use of a \emph{system}.
\emph{System designer} and \emph{application designer/programmer} are
defined accordingly. As an example, when we
discuss the design of Slope, we wear the hat of a system designer, and when
discussing how an application is programmed to run on top of Slope, we act as
an application designer.

In distributed applications, data access locality and load balancing
are two important factors influencing their performance. However,
optimizing each of these usually requires the programmer to make certain
compromises.

Let us take communication between application instances as an example.
Instances can communicate using well-known techniques such as message passing
or distributed shared memory, but some applications do not benefit from the
generality of these methods even though they have to tolerate the performance
overhead coming with their extra functionality. For example applications whose
computation is expressed through the MapReduce \cite{dean2008mapreduce}
framework can rarely benefit from access to a
global shared memory in a synchronized manner.

An interesting property of these applications is that their
restricted data access pattern opens up an opportunity to trade-off simplicity
of design to gain better performance. That is, we have the choice of using more
strict programming models and losing some of the design flexibility that we
were not using anyway, to get an edge in performance by getting rid of the
overheads that are present only to handle use cases that we are not interested
in.

One ubiquitous subset of applications with such a property are
ones with data that is partitionable such that the majority of data
accesses from one operation fall in that one partition only.
This is desirable because it improves access locality, as
long as we can balance the load across the cluster. Therefore the work of
the application designer in these systems boils down to partitioning data and
operations to minimize cross-partition requests, and find a strategy to
distribute the load of the partition evenly across the cluster.

These applications may randomly partition data (e.g., in-memory distributed
hash tables) or partition the data based on the values from particular fields
in the data (e.g., web application
user behavior statistics).


\section{Solving the locality/load balancing equation}
\paragraph{}
Most of these applications have specific data access or data sharing patterns.
These patterns are the results of designing specialized systems such as
BigTable \cite{chang2008bigtable} for specific use cases.
By designing the application logic/algorithms based on its data access patterns,
we achieve better performance compared
to designing the logic/algorithms without taking into account useful properties of
how application data is accessed.

This strategy improves performance but propagates design complexities
down to the level of the core algorithms in the application. As an example, suppose
one machine in a distributed hash table cluster becomes a hotspot.
One way of dealing with this situation would be for the system to somehow stop
the incoming flow of requests to one of the hot shards, serialize that shard,
send it to a machine with less load, and re-route all the requests to that node.
Apart from the unavailability of the system during the transfer, the
serialization incurs both a performance penalty in run-time, and code complexity
which creeps into the design of the hash table and its core algorithms.

Design decisions like this make applications harder to maintain as their
core algorithms will become dependent on low level system properties.
In such an application the algorithms and data structures which the system uses
are no longer well defined black boxes that can be seamlessly improved. As a
result, the overall design of the system will be closed to additions, and we
will be stuck with restricted APIs and specific guarantees on how they work.
While changing the internal algorithms, we must worry about not breaking our own
conditions of data management. Furthermore, our solution will be inflexible and
won't generalize to similar problems in the future.

The above situation arises when system designers design
core algorithms with data partitioning in mind, providing solutions for two
problems at the same time. The issue is that in doing so, they typically have to
trade-off programmability and maintainability, while making their overall design
more complex.

\section{Problem statement}
Instead of allowing the core logic layer and the sharding layer to interfere,
we can instead ask if it is possible to attend to each problem separately and
reach a balance between performance improvement and programmability.

Is it possible to select a subset of partitionable applications
and provide well defined machinery for their data sharing? If this data sharing
framework supports moving the partitions between the machines with minimal
interference with the algorithms' execution inside the partition, without
sacrificing performance (e.g., through serialization and deserialization), the
application designers can comfortably design \emph{single partitions}, instead
of \emph{whole distributed systems}.

The platform will then ensure that each partition can run correctly, while
allowing application partitions to migrate between machines in the cluster
to prevent over-subscription of the resources of each machine. As a result,
Not only will the application achieve load balancing without
much effort,
but also it will end up with a simpler design, with all
of the logic for a distributed environment being managed by the framework,
out of the core application code.

% \TODO{How do I write something general about data locality and load imbalance?}
% The use of in-memory data processing systems has recently grown as a result of
% different advances in computer hardware. Lower operating cost of DRAM means we
% are incentivized to design systems that sacrifice memory usage for performance.
% Faster network interconnects reduce the latency of communication between
% machines, minimizing the performance cost of scaling out server software.
% Analogically similar to the above, persistent memory tightens the performance
% gap between in-memory data processing and file system persistence layer,
% allowing applications to persist data structures as fast as they can use them
% in main memory, as they are kept consistent across operations.
%
% \TODO{citations?}
% these improvements have collectively and independently cast doubt on the precondition of
% ``slow devices, fast CPU'' by gradually shifting both latency and throughput
% bottlenecks towards the classical position of the processor and the kernel.
% This had encouraged research towards building systems which manage their
% network communication and storage more closely. User space networking \TODO{ cite
% DPDK and/or the likes and things that use them? what else?} and managing high
% traffic data structures like hash-tables and balanced binary search trees
% \TODO{mention masstree or similar, and some usages?} in the application are
% both research trends in developing what we call \emph{data structure centric}
% applications \TODO{citations/examples?}. Indeed the operating system kernel provides networking and high
% level interface to useful data structures (e.g., through the interface of file
% systems) but for high performance applications, the performance gain from using
% a specialized way of managing data is worth the complexity.
% Some of these systems target low latency, but all of them have to provide
% a solution for higher throughput workloads. As we exhaust the resource limits
% of a single machine, this becomes synonymous to how the system scales out to
% multiple machines.\TODO{suitable point to break the paragraph?}
% 
% In multi-machine environments, any non-trivial (read-only in essence) system
% faces problems that also become apparent when we cross the single-threaded
% to multi-threaded boundary: how to manage accesses to shared data and where to
% schedule computations. These in part translate to two separate objectives in
% the design of data structure centric distributed systems. \TODO{should I use a
% hyphen in there?} \TODO{is centric a word?}
% \begin{itemize}
%     \item How to keep computation close to the data that it uses (Locality)
%     \item Where to process each request to avoid overloading any of the machines (Load balancing)
% \end{itemize}
% 
% 
% 
% 
% 
% \section{Locality and load balancing}
% System designers have came up with various solutions to to keep their
% computations as close as possible to their data.
% 
% Some applications can tolerate relaxed guarantees for how reads and writes are
% executed. \TODO{mention a few examples and their requirements?}
% Typically replicas are or can be used in these applications as they can be
% used to process certain (particularly read-only) requests based on the
% consistency requirements of the system.
% 
% Not paying attention to the locality constraints and remote access penalties
% and simply contending for resources results (e.g., optimistic concurrency
% control) will result in poor performance in workloads with highly contended
% accesses.
% 
% \begin{figure}[hbt!]
% 
% 
% \begin{tikzpicture}[baseline]
% \begin{axis}[
% width=7cm,
% xmin=1,xmax=28,
% ymin= 0,ymax=1400,
% xlabel=Number of writer threads,ylabel=Average write latency(cycles),
% xtick={1,4,8,...,28},
% ytick={1,200,400,...,1400},
% ]
% \addplot coordinates{
%   (1,9) (2,65) (3,91) (4,139) (5,194) (6,278) (7,299) (8,394) (9,456) (10,425)
%   (11,464) (12,505) (13,546) (14,592) (15,699) (16,688) (17,732) (18,849)
%   (19,820) (20,866) (21,1058) (22,990) (23,1046) (24,1090) (25,1225) (26,1251)
%   (27,1308) (28,1318)
% };
% \end{axis}
% \end{tikzpicture}%
% ~%
% %
% \begin{tikzpicture}[baseline]
% \begin{axis}[
% width=7cm,
% % xmin=0,xmax=32,
% % ymin= 0,ymax=0.10,
% xlabel=Number of worker coroutines per thread,ylabel=Successful transactions,
% xtick={1,5,10,20,30},
% ytick={200000,400000,600000,800000,1000000},
% ]
% \addplot coordinates{
%     (1,730000) (5,870000) (10,600000) (20,200000) (30,50000)
% };
% \end{axis}
% \end{tikzpicture}%
% 
% \caption{
%     The left figure, similar to one from \cite{boyd2014oplog}, shows how
%     performance degrades as different cores contend on a lock for synchronized
%     write access to a shared byte. To remedy this, they propose a batching
%     technique. The right figure shows how increasing
%     the number of coroutines in a distributed transaction processing system
%     \cite{kalia2016fasst} impacts performance on a contended workload.
%       }
% \label{fig:contention_penalty}
% 
% \end{figure}
% 
% Sharding techniques are also used extensively, allowing system designers to
% choose almost any point in the spectrum of design space between high-locality;
% coarser load balancing (e.g., partitioning user data by user id) and
% low-locality; better load balancing (e.g., random sharding).
% 
% An important property of some of these designs is modularity, as
% a result of the problem space being composable, with similarities to how the
% memory
% hierarchy is laid out and how similar problems arise at every level. For
% example all of the above remain
% relevant even after one ``layer'' of randomly sharding the data or the requests,
% as the designer of the system is yet to decide what is the consistency
% requirements of the system within and in between the shards, as well as
% enjoying the freedom of applying other techniques in the higher layers.
% This suggests that
% it would make sense for the solutions targeting locality and
% load balancing to attend to a particular horizontal slice of the problem,
% limiting the conditions and requirements. For example a high performance
% locking scheme can choose to provide the flexibility to be incorporated in a
% sharding scheme to manage cross-partition accesses, as opposed to being bound
% be used in a specific partitioning scenario.
% Not only this guideline
% will make the design of systems simpler and more effective, it allows us to
% fuse independent solutions for different locality and load balancing
% sub-problems when designing a system.
% 
% With that in mind, we have limited our target domain to the ``layer'' where each
% subset of read and write requests can be encapsulated with the data structures
% that they need to access, creating a scheduling unit which along with its
% respective computation, will be placed on a single machine. The way the
% application organizes its workload into these units (upper design layers)
% and what the system decides to do inside each one of these units (lower design
% layers), as well as how these units communicate, will be left to the
% application, which will be responsible for all the plumbing, with the gained
% benefit of composability of different solutions.
% 
% 
% \TODO{Is this section full of useless jargon? Are there too quick shifts from general hand waving
% to specific details? Does it get a message through? Do we need to change the
% section title? Would a figure be useful?}

\section{Contributions}
We extend the notion of migratability that is
introduced in RAMP \cite{memon2018ramp} to data structures and in general,
self-containing units of work in distributed applications.
We introduce
the properties of migration-friendly applications in the real world and discuss
how they would interface with an object-based migration platform, in a way
that is useful in real scenarios outside of the lab environment.

We then present the design of Slope, an object-based migration framework
and its implementation in C++ using RDMA networking (\hyperlink{https://github.com/farnasirim/slope}{https://github.com/farnasirim/slope}) and present measurements
of different operations in Slope, to show how migration affects application
performance.
To conclude, we provide an overview of the shortcomings of Slope and
discuss possible future directions to improve the migratable programming model.

