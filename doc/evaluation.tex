\chapter{Evaluation}
\label{chap:evaluation}

We go over a few use cases of Slope in real-world systems and present
benchmarks for select applications. We also discuss
the metrics that the applications using Slope can measure to get a sense of
how much Slope is impacting their performance.

In our test cluster each machine is equipped with an Intel Xeon E5-2680 CPU,
128 GBs of physical memory and a 100Gbps ConnectX-4 Infiniband RDMA-capable
network adapter. We are running Linux Kernel version 4.19.49.

To measure times and calculate performance metrics globally in the cluster,
we synchronize the start time from one machine to all other machines in the
cluster, by estimating the round trip time between them, which we do by
calculating the median among multiple round trip time calculations. Round
trip times are approximately $5 {\mu}{s}$, a pessimistic upper bound for the
error in time synchronization.

To make sure our graphs are accurate, we run each configuration at least 5 times
and average out the results, and in some cases, drop the min and max values to
eliminate the outlying points. That means each point in each of our graphs is
the resulting value from the above calculation on multiple runs with the same
configuration. Even without eliminating the outlying points, the standard errors
of our measurements are negligible (i.e. multiple orders of magnitude smaller)
compared to the reported values, unless otherwise stated.


Looking at each sub-system in Slope, one can define certain metrics that
reflect if that sub-system is working efficiently. For example we measure
the elapsed time until the prefill operation completes. We also measure
other metrics which more directly impact application performance, such as
end to end migration delay or time during which the object is unusable at
either end.

\subparagraph{Migration friendliness of data structures:}
Based on how the migration process and specifically how the prefill operation
works, objects which use their internal memory in a ``fixed'' manner, that is
without doing much memory allocation/deallocation, are very good candidates
for migration, since they can function seamlessly throughout the prefill phase,
by only inducing dirty page overhead.

Examples of these objects include bloom filters, where we have a fixed
array of bits the size of which always stays the same.
Similarly hash tables which use open addressing techniques such as cuckoo
hashing scheme for their collision resolution are also good candidates for the
same reason.
Apart from these objects which make the best-case scenario for Slope, we also
discuss migrating a generic object whose allocation/deallocation patterns are not
ideal.

\section{Case study: core metrics and STL objects}
\subsection{Migrating a vector with clean pages}
\label{sec:cleanvec}

\begin{figure}[tp]
    \begin{center}
        \input{bench-readonly.pgf}
    \end{center}
    \caption{Migration statistics of a clean vector (4KB pages)}
    \label{fig:vectorreadonly}
\end{figure}

\begin{figure}[tp]
    \begin{center}
        \input{bench-readonly-hp.pgf}
    \end{center}
    \caption{Migration statistics of a clean vector (2MB huge pages)}
    \label{fig:vectorreadonlyhp}
\end{figure}

In our simplest example, we create a \texttt{vector}, initialize it with the
pre-specified size and migrate it to the destination. Approximately $8$ lines
of code are required on each of the source and destination sides to reproduce
this operation, excluding lines that serve the purpose of gathering statistics.
\autoref{fig:vectorreadonly} depicts the results.

Naturally, the prefill phase takes up most of the transfer time, which grows
linearly by increasing the size of the object. The increasing gap between the
prefill duration and the end to end latency can be attributed to the number
of syscalls that Slope makes that grow linearly with the
number of pages that are transferred before or after the prefill phase. The
time it takes to turn over the ownership is not impacted by the
size of the object and oscillates between tens of microseconds and hundreds
of microseconds. This is expected as this step consists of a single RDMA SEND.

\autoref{fig:vectorreadonly} shows that we are using about a hundredth of our 100 Gbps
network bandwidth. The prefill phase is highly CPU bound as it involves no
synchronization between different threads, no operation that blocks the data
transfer, and no other threads that compete to run on the CPU.
To use the
network bandwidth more effectively, we can increase the granularity of our
memory allocation unit by using 2MB huge pages. \autoref{fig:vectorreadonlyhp} shows
how using 2MB huge pages allows us to use around a fifth of our network bandwidth.
Furthermore, a 500-fold decrease in the number of allocation units decreases
the overall CPU cycles we spend for per-page operations in the memory allocator
and the control and data planes.

\subsection{Migrating a vector while dirtying all of its pages}
\label{sec:dirtyvector}
\begin{figure}[tp]
    \begin{center}
        \input{bench-writeall.pgf}
    \end{center}
    \caption{Migration statistics of a vector with all pages dirty (4KB pages)}
    \label{fig:vectorwriteall}
\end{figure}

\begin{figure}[tp]
    \begin{center}
        \input{bench-writeall-hp.pgf}
    \end{center}
    \caption{Migration statistics of a vector with all pages dirty (2MB huge pages)}
    \label{fig:vectorwriteallhp}
\end{figure}

In this micro-benchmark, we create a vector, dirty all of its pages after the
prefill phase has finished, and then finalize the transfer. Compared to the
clean scenario in \autoref{sec:cleanvec}, we need to spend extra time to
retransfer the dirty pages.

\autoref{fig:vectorwriteall} shows the result. As we would expect, the time it takes to turn over
the object ownership remains unchanged, however based on the usage of the
application, there will be a period during which the object is read-only on the
sender's side and the writes will be delayed on the receiver's side. We
explore the implications of this in \autoref{sec:evalmigfriendly} and
\autoref{sec:evalgenericobj}.

Although the same set of pages are sent/received during the prefill phase and
transferring of the dirty pages, the former takes considerably longer. This
happens because we do not need to pin the object memory to physical memory all
over again on each side.

Similar to the case with a read-only vector, we repeat the experiment with huge
pages. \autoref{fig:vectorwriteallhp} shows the result. The result resembles
those in \autoref{fig:vectorreadonlyhp}, except here the elapsed time excluding the
prefill duration and the dirty page transfer duration is still significant. This
is contributed by the source machine having to execute the signal
handler while looping over the pages and dirtying them, after the
prefill phase and before the final transfer phase.


\section{Case study: bloom filter}
\label{sec:evalmigfriendly}

\begin{figure}[tp]
    \begin{center}
        \input{bench-bloomfilter.pgf}
    \end{center}
    \caption{Migration timeline of a bloom filter (4KB pages)}
    \label{fig:bloomfilter}
\end{figure}


\begin{figure}[tp]
    \begin{center}
        \input{bench-bloomfilter-hp.pgf}
    \end{center}
    \caption{Migration timeline of a bloom filter (2MB huge pages)}
    \label{fig:bloomfilterhp}
\end{figure}


In this section we discuss the case for migrating a bloom filter while it is
being queried. A bloom filter is a migration-friendly object because
no operation on the bloom filter causes a memory allocation after we initialize
the object. The supported operations (put, get) only read or modify memory
locations.

At the start of the benchmark, two bloom filter objects, BF1
and BF2, are on the source machine. There is no bloom filter on the destination,
making the source machine overloaded in this scenario. On each machine there
are two threads, a reader and a writer, each of which uniformly chooses among
the available bloom filter objects available on the local machine to send their
respective query (get, put) to. In this benchmark the size of each of the bloom
filters is close to 800MB.

\autoref{fig:bloomfilter} shows the timeline of the events and the throughput
of each of the operations on the two bloom filter objects present in the system
on either of the machines as we migrate BF1. We are using 4KB pages in this
case and BF1 consists of 200,000 pages. Around 60\% of those were dirtied during
the migration.

During the prefill period (~2200ms to ~7000ms), both objects see a decrease in
the number of writes. As the writer thread gets blocked inside the signal
handler while writing to the BF1 object, both BF1 and BF2 writes are equally
impacted since they equally share the writer thread. On the other hand, read
throughput on both objects stays the same as the reader thread never gets
blocked.

At around 7000ms we take away the write access to BF1 from the source, but
reads continue unimpacted until around 8700ms, where we take away the read
access too. At 8700ms the final transfer phase starts and until 9000ms,
the destination prepares its memory locations by calling into the operating
system and the memory allocator for each page that is being transferred.

At around 9300ms, the first read and write operations on the destination
succeed as the transfer of underlying memory for outstanding read/write
operations is prioritized. At around 10700ms, the migration is complete and
each of the BF objects is on a separate machine, doubling the overall
throughput.


\autoref{fig:bloomfilterhp} shows the same timeline in the case of using
huge pages. During the prefill phase 383 pages were transferred and
256 of them were dirtied by writes. The overall flow of operations is similar
to the previous case, but
the application enjoys much shorter times across all metrics including the
end to end latency and read and write unavailability periods.

\section{Case study: Hash table partition}
\label{sec:evalgenericobj}
In this benchmark we discuss the case of migrating a hash table partition. We
use \texttt{std::map} which is migration unfriendly because of the possibility
of frequent memory allocations.


\begin{figure}[tp]
    \begin{center}
        \input{bench-map.pgf}
    \end{center}
    \caption{Migration timeline of a map (4KB pages)}
    \label{fig:map}
\end{figure}

\begin{figure}[tp]
    \begin{center}
        \input{bench-map-hp.pgf}
    \end{center}
    \caption{Migration timeline of a map (2MB huge pages)}
    \label{fig:maphp}
\end{figure}


Each machine shares its processing time among the hash table partitions that
it owns. Initially, the target partition (MP) is owned by the source machine, but half of
the processing time of the source machine is allocated to another partition that
it owns (throughput for this other partition is omitted for brevity). As a result
the source machine decides to migrate MP to the destination machine, where MP
can use the available CPU time to achieve better throughput.

\autoref{fig:map} and \autoref{fig:maphp} show the timeline and the throughput
over time of the MP object as it is being migrated with 4KB and 2MB pages
respectively. Insert operations add new elements to the map, updates change
the value of a key in-place, and reads query a key. After starting the migration
we are no longer allowed to issue insert operations as they would require
memory allocations.

At the start of the prefill phase starting at 100ms, MP has grown to around 40MB.
During the long prefill phases, read and write operations on MP continue and as
a result, half of the pages in the 4KB pages case, and 23 out of the 24 pages in the
2MB page case are dirtied. Even though the finer grain 4KB pages detected the
dirty memory locations more accurately, huge pages outperformed 4KB pages in all
metrics in all configurations (MP size, read/write window closure duration,
dirty page percentage, etc.) of this workload, thanks to the 100Gbps network
throughput.

The end to end latency in this scenario is large but is not an important
performance factor because the operations
on the map that were needed to dirty the underlying pages of MP dominate
the migration duration.

Our benchmarks show that Slope can benefit from larger memory units, as they
allow us to take better advantage of our network hardware. We can also make
more use of the available bandwidth by carrying out the migration steps using
multiple threads on the Slope side. This may complicate the communication
between the application and Slope during the migration, but allows us to
saturate the network bandwidth.

% \TODO{this model encourages fixed objects, where you don't need to allocate repeatedly: bloom filter, hash table with fixed size values + ds's where access is local}
%\TODO{build a function as a service framework on this}
%\TODO{can this be used for other systems such as parallel processing
% based on actor models and message queues with efficient support for
%e.g., fan out}
% supporting read-only operations and even write operations with carefully
% created static buffers that can contain unsupported (those that allocate/deallocate)
% operations that the object has received after a call to initiate migration has
% already been made.
% big table can be implemented easily using Slope
% as opposed to the original methods where we only think about the movement of
% objects, here we think about movement of servers
