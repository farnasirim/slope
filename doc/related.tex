\chapter{Related Work}
\label{chap:related}
In this section we discuss how research on smililar topics relates to
Slope, what makes Slope different, and how ideas from prior work across
multiple categories can be incorporated into Slope in the future.

\section{RAMP}
Slope borrows the notion of shared address spaces from RAMP
\cite{memon2018ramp}. This closely relates RAMP and Slope and therefore
a rundown of the differences between the two systems can be helpful.

\subsection{Programmability}
Slope makes data structures or more generally, self-contained units of
work migratable in a black box fashion, without forcing modifications to
their implementations in existing applications.
This means that any C++ entity which is capable of using a custom
allocator, including STL containers, can be made migratable through Slope
with almost zero extra programming effort. Furthermore Slope benefits
from the composition friendliness of the objects that conform to C++ 
allocator named requirement, making it easy to create complex migratable
types from simple building blocks.

RAMP in contrast not only discusses the
migration of memory segments,
but also uses a stateful memory allocator which makes it
backwards incompatible with existing C++ software.

\subsection{Usability}
We present a programming model for migratable objects which makes them
usable in at least two broad families of applications as discussed in
\ref{sec:api}, showing how this model can be used for high performance
applications in the real world.

On the other hand, RAMP introduces a bare bones memory segment migration
platform which outside of a controlled experiment will be at most as
useful as an RDMA-based transport, if at all usable,
because of the reasons discussed in the \ref{subsec:sendrecmig}.

\subsection{Migration performance}
Based on the type of workload, Slope benefits from prefilling the
destination machine's memory, resulting in smaller hand-off times and
quicker convergence to the steady state throughput.


RAMP only starts transferring the contents of a memory segment after
the segment ownership has been transferred. This results in its
convergence period or its window of unresponsiveness to go up to hundreds
of milliseconds for a 128 MB segment, while based on the type of
workload, Slope can finish the migration with as low as 10us with
negligible throughput distortion.

In Slope the number of parallel migrations between \emph{each pair}
of machines at any given time is only bounded by the number of receives
pre-posted to their queue pairs, whereas in RAMP, at any point in time
there can be at most a single migration in the \emph{whole cluster}.


\subsection{Memory allocation performance}
Slope uses pooled memory allocation and lazy deallocations to handle
memory allocation in a peer-to-peer fashion.

RAMP however uses a Zookeeper cluster to keep track of memory allocations.
Not only relying on an external service during run-time, which possibly
operates on a slower network performs worse under heavy load, but also it
is susceptible to contention when multiple servers race to allocate memory segments.


\section{Shared memory and RDMA based systems}
Herd \cite{kalia2016designguidelines} discusses guidelines that can be
used by RDMA applications for improved performance. We used many of their
insights in our implementation.

Multiple systems have provided designs
for high performance RPC, transaction processing, or shared memory over
RDMA. These range from eRPC \cite{kalia2019datacenter}, a general purpose
RPC framework which communicates in raw packet format over unreliable
datagram, to FaRM \cite{Dragojevic2014FaRM} which uses one-sided RDMA
verbs in conjunction with busy polling to provide a remote shared memory
abstraction with support for transactions. Examples from other design
points in this spectrum include FaSST \cite{kalia2016fasst}, which uses
unreliable datagram and combines low level design techniques such as
request batching, coroutines, and QP sharing to achieve high throughput
in transaction processing, ScaleRPC \cite{ScaleRPC2019} which again uses unreliable datagram,
and Storm \cite{novakovic2019storm} which
focuses on in-memory data structures and uses
one-sided and two-sided RDMA verbs in conjunction in a hybrid fashion.

Some of these systems have partially overlapping problem statements with
Slope. They target high distributed transaction throughput while limiting
the programming model to transaction processing or RPCs.
This direction only aligns with the goals of Slope in the cases where we
need to migrate a large number of relatively small objects. This suggests
that an RPC communication model might be better suited for such an
application than the migration model. Nevertheless, these systems
can be plugged into Slope as its control plane to improve its performance
in the cases where there are relatively large number of objects being
migrated at certain points in time.

Given that the design of Slope focuses on in memory data structures, there
is a lot of potential in using specialized memory hardware. DrTM
\cite{drtm2017} builds on hardware transactional memory and RDMA
to achieve high throughput transaction processing.
Hotpot \cite{Shan2017distributed} and Octopus \cite{Lu2017rdmadistributed}
use persistent memory to build distributed shared memory.


\section{Database migration and replication}
\TODO{find a new home for derecho}
Derecho \cite{jha2019derecho} aims to provide state machine replication
for cloud applications and shares some core concepts with Slope, for
    example in how they define their system around a data flow model.
    The main idea behind their approach to handling failures can be
    incorporated in Slope to implement a form of snapshot isolation at
    migration boundaries.

ProRea \cite{ProRea2013} and Zephyr \cite{zephyr2011elmore} are live
database migration methods similar in terminology Slope which is a
data structure migration engine. However in these systems much effort goes
towards conflict resolution and handling the ``dual ownership''
time-window, whereas in Slope we avoid dual ownership of objects
altogether to support the notion of the objects being memory resident
rather than view them as entries in a storage system.
